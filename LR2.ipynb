{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "173e6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c0c87f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c708fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d504dc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                  0\n",
       "radius_mean                1\n",
       "texture_mean               0\n",
       "perimeter_mean             1\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             1\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             1\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 2\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            1\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c6d55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling\t1 null value(s) in radius_mean with mean value -->\t14.116125000000011\n",
      "Filling\t1 null value(s) in perimeter_mean with mean value -->\t92.02346830985917\n",
      "Filling\t1 null value(s) in concavity_mean with mean value -->\t0.08892480757042255\n",
      "Filling\t1 null value(s) in compactness_se with mean value -->\t0.02546582922535212\n",
      "Filling\t2 null value(s) in area_worst with mean value -->\t881.4024691358021\n",
      "Filling\t1 null value(s) in concavity_worst with mean value -->\t0.27245536443661955\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns[df.isnull().any(axis=0)]:\n",
    "    mean = df[i].mean()\n",
    "    print(f'Filling\\t{df[i].isna().sum()} null value(s) in {i} with mean value -->\\t{mean}')\n",
    "    df[i].fillna(mean , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d5d8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the data, the .values converts to numpy array\n",
    "df_train = df.sample(frac=0.67,random_state=42)\n",
    "df_test = df.drop(df_train.index)\n",
    "\n",
    "X_train = df_train.drop('diagnosis', axis = 'columns').values\n",
    "# X_train = np.c_[np.ones(len(X_train)), X_train]\n",
    "X_test = df_test.drop('diagnosis', axis = 'columns').values\n",
    "# X_test = np.c_[np.ones(len(X_test)), X_test]\n",
    "\n",
    "y_train = df_train['diagnosis'].values\n",
    "y_train[y_train == 'M'] = 1\n",
    "y_train[y_train == 'B'] = 0\n",
    "y_test = df_test['diagnosis'].values\n",
    "y_test[y_test == 'M'] = 1\n",
    "y_test[y_test == 'B'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "382600db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.mean(axis=0))/(X_train.std(axis=0))\n",
    "X_test = (X_test - X_test.mean(axis=0))/(X_test.std(axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4000034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.c_[np.ones(len(X_train)), X_train]\n",
    "X_test = np.c_[np.ones(len(X_test)), X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dac792e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STARTING OFF WITH THE LOGISTIC REGRESSION CLASS\n",
    "\n",
    "class Logreg:\n",
    "    def sigmoid(self, x):\n",
    "        sig = 1/(1 + np.exp(-x))\n",
    "        return sig\n",
    "  \n",
    "    def __init__(self):    #constructor\n",
    "        self.weights = None #bias lite for now\n",
    "        \n",
    "        \n",
    "    def graddesc(self, X, y, learnrate):\n",
    "        self.weights = np.zeros(df.shape[1]) #bias lite for now\n",
    "        costs = []\n",
    "        iters = []\n",
    "        for j in range(0, len(X)): #will run 569 times -- basically 1 epoch, it will run through all of the inputs present at least once\n",
    "                self.weights = self.weights - learnrate*(X[j].T*(self.sigmoid(np.dot(self.weights,X[j])) - y[j]))#the gradient function is (tn - yn) DOT x\n",
    "                costs.append(self.compute_cost(self.sigmoid(np.dot(self.weights,X[j])),y[j]))\n",
    "                iters.append(j)\n",
    "        #plt.plot(iters,costs)\n",
    "        return\n",
    "    \n",
    "    def compute_cost(self, predictions, actual):\n",
    "        #m = len(actual)\n",
    "        log_of_predictions = np.log(predictions+0.000000000000001)\n",
    "        log_of_oneMinusPredictions = np.log(1-predictions+0.000000000000001)\n",
    "        cost = -1*(np.sum(((actual*log_of_predictions) + ((1-actual)*(log_of_oneMinusPredictions)))))\n",
    "        return cost\n",
    "    \n",
    "    def classify(self, X, threshold):\n",
    "        predicts = np.zeros(len(X))\n",
    "        for j in range (0, len(X)):\n",
    "            if(self.sigmoid(np.dot(self.weights, X[j])) >= threshold):\n",
    "                predicts[j] = 1\n",
    "            else:\n",
    "                predicts[j] = 0\n",
    "        return predicts\n",
    "    \n",
    "    def sigmoidpredictors(self, X):\n",
    "        predicts2 = np.zeros(len(X))\n",
    "        for j in range (0, len(X)):\n",
    "            predicts2[j] = self.sigmoid(np.dot(self.weights, X[j]))\n",
    "        return predicts2\n",
    "    \n",
    "    def metricscore(self, y_actual, y_out):\n",
    "        truepos = 0;\n",
    "        falsepos = 0;\n",
    "        trueneg = 0;\n",
    "        falseneg = 0;\n",
    "        for i in range(len(y_actual)):\n",
    "            if(y_actual[i] == y_out[i]):\n",
    "                if(y_actual[i] == 0):\n",
    "                    trueneg = trueneg + 1;\n",
    "                else:\n",
    "                    truepos = truepos + 1;\n",
    "            else:\n",
    "                if(y_out[i] == 0):\n",
    "                    falseneg = falseneg + 1;\n",
    "                else:\n",
    "                    falsepos = falsepos + 1;\n",
    "        return truepos, falsepos, trueneg, falseneg\n",
    "    \n",
    "    def accuracy(self , y_actual , y_out): #taking the accuracy as the number of correct predictions / total number of predictions\n",
    "        acc = np.sum(y_actual == y_out)/len(y_out)\n",
    "        return acc\n",
    "    \n",
    "    def precision(self, y_actual, y_out):\n",
    "        tp, fp, tn, fn = self.metricscore(y_actual, y_out)\n",
    "        prec = tp/(tp + fp)\n",
    "        return prec\n",
    "    \n",
    "    def recall(self, y_actual, y_out):\n",
    "        tp, fp, tn, fn = self.metricscore(y_actual, y_out)\n",
    "        #rec = np.sum(y_actual == y_out and y_out == 1)/np.sum((y_actual == y_out and y_out == 1) or (y_actual != y_out and y_out == 0))\n",
    "        rec = tp/(tp + fn)\n",
    "        return rec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c517fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchLogreg:\n",
    "    def sigmoid(self, x):\n",
    "        sig = 1/(1 + np.exp(-x))\n",
    "        return sig\n",
    "  \n",
    "    def __init__(self):\n",
    "        self.weights = None #bias lite for now\n",
    "        \n",
    "        \n",
    "    def graddesc(self, X, y, learnrate, batchSize, epochs):\n",
    "        self.weights = np.zeros(df.shape[1]) #bias lite for nwo\n",
    "        errors = np.zeros(df.shape[1])\n",
    "        costs = []\n",
    "        iters = []\n",
    "        a = 0\n",
    "        for e in range(0, epochs):\n",
    "            for i in range(0, len(X)-batchSize+1):\n",
    "                cost1 = 0\n",
    "                for j in range(i, batchSize+i): #will run 569 times -- basically 1 epoch, it will run through all of the inputs present at least once\n",
    "                    errors = errors + X[j].T*(self.sigmoid(np.dot(self.weights,X[j])) - y[j])#the gradient function is (tn - yn) DOT x\n",
    "                    cost1 = cost1 + self.compute_cost(self.sigmoid(np.dot(self.weights,X[j])),y[j])\n",
    "                    i=i+1\n",
    "                    a=a+1\n",
    "                cost1 = cost1/batchSize\n",
    "                costs.append(cost1)\n",
    "                iters.append(a)\n",
    "                self.weights = self.weights - learnrate * errors\n",
    "        #plt.plot(iters, costs)\n",
    "        return\n",
    "    \n",
    "    def compute_cost(self, predictions, actual):\n",
    "        \n",
    "        log_of_predictions = np.log(predictions+0.000000000000001)\n",
    "        log_of_oneMinusPredictions = np.log(1-predictions+0.000000000000001)\n",
    "        cost = -1*(np.sum(((actual*log_of_predictions) + ((1-actual)*(log_of_oneMinusPredictions)))))\n",
    "        return cost\n",
    "    \n",
    "    def classify(self, X, threshold):\n",
    "        predicts = np.zeros(len(X))\n",
    "        for j in range (0, len(X)):\n",
    "            if(self.sigmoid(np.dot(self.weights, X[j])) >= threshold):\n",
    "                predicts[j] = 1\n",
    "            else:\n",
    "                predicts[j] = 0\n",
    "        return predicts\n",
    "    \n",
    "    def metricscore(self, y_actual, y_out):\n",
    "        truepos = 0;\n",
    "        falsepos = 0;\n",
    "        trueneg = 0;\n",
    "        falseneg = 0;\n",
    "        for i in range(len(y_actual)):\n",
    "            if(y_actual[i] == y_out[i]):\n",
    "                if(y_actual[i] == 0):\n",
    "                    trueneg = trueneg + 1;\n",
    "                else:\n",
    "                    truepos = truepos + 1;\n",
    "            else:\n",
    "                if(y_out[i] == 0):\n",
    "                    falseneg = falseneg + 1;\n",
    "                else:\n",
    "                    falsepos = falsepos + 1;\n",
    "        return truepos, falsepos, trueneg, falseneg\n",
    "    \n",
    "    def accuracy(self , y_actual , y_out): #taking the accuracy as the number of correct predictions / total number of predictions\n",
    "        acc = np.sum(y_actual == y_out)/len(y_out)\n",
    "        return acc\n",
    "    \n",
    "    def precision(self, y_actual, y_out):\n",
    "        tp, fp, tn, fn = self.metricscore(y_actual, y_out)\n",
    "        prec = tp/(tp + fp)\n",
    "        return prec\n",
    "    \n",
    "    def recall(self, y_actual, y_out):\n",
    "        tp, fp, tn, fn = self.metricscore(y_actual, y_out)\n",
    "        #rec = np.sum(y_actual == y_out and y_out == 1)/np.sum((y_actual == y_out and y_out == 1) or (y_actual != y_out and y_out == 0))\n",
    "        rec = tp/(tp + fn)\n",
    "        return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "084fba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchLogreg:\n",
    "    def sigmoid(self, x):\n",
    "        sig = 1/(1 + np.exp(-x))\n",
    "        return sig\n",
    "  \n",
    "    def __init__(self):\n",
    "        self.weights = None \n",
    "        \n",
    "    def compute_cost(self, predictions, actual):\n",
    "        \n",
    "        log_of_predictions = np.log(predictions+0.000000000000001)\n",
    "        log_of_oneMinusPredictions = np.log(1-predictions+0.000000000000001)\n",
    "        cost = -1*(np.sum(((actual*log_of_predictions) + ((1-actual)*(log_of_oneMinusPredictions)))))\n",
    "        return cost\n",
    "        \n",
    "    def graddesc(self, X, y, learnrate, epochs):\n",
    "        self.weights = np.zeros(df.shape[1]) \n",
    "        errors = np.zeros(df.shape[1])\n",
    "        costs = []\n",
    "        iters = []\n",
    "        for i in range(0, epochs):\n",
    "            cost1 = 0\n",
    "            for j in range(0, len(X)): \n",
    "                errors = errors + X[j].T*(self.sigmoid(np.dot(self.weights,X[j])) - y[j])\n",
    "                cost1 = cost1 + self.compute_cost(self.sigmoid(np.dot(self.weights,X[j])),y[j])\n",
    "            cost1 = cost1/len(X)\n",
    "            self.weights = self.weights - learnrate * errors\n",
    "            costs.append(cost1)\n",
    "            iters.append(i)\n",
    "        #plt.plot(iters, costs)\n",
    "        return costs\n",
    "    \n",
    "    def sigmoidpredictors(self, X):\n",
    "        predicts2 = np.zeros(len(X))\n",
    "        for j in range (0, len(X)):\n",
    "            predicts2[j] = self.sigmoid(np.dot(self.weights, X[j]))\n",
    "        return predicts2\n",
    "    \n",
    "    def classify(self, X, threshold):\n",
    "        predicts = np.zeros(len(X))\n",
    "        for j in range (0, len(X)):\n",
    "            if(self.sigmoid(np.dot(self.weights, X[j])) >= threshold):\n",
    "                predicts[j] = 1\n",
    "            else:\n",
    "                predicts[j] = 0\n",
    "        return predicts\n",
    "    \n",
    "    def metricscore(self, y_actual, y_out):\n",
    "        truepos = 0;\n",
    "        falsepos = 0;\n",
    "        trueneg = 0;\n",
    "        falseneg = 0;\n",
    "        for i in range(len(y_actual)):\n",
    "            if(y_actual[i] == y_out[i]):\n",
    "                if(y_actual[i] == 0):\n",
    "                    trueneg = trueneg + 1;\n",
    "                else:\n",
    "                    truepos = truepos + 1;\n",
    "            else:\n",
    "                if(y_out[i] == 0):\n",
    "                    falseneg = falseneg + 1;\n",
    "                else:\n",
    "                    falsepos = falsepos + 1;\n",
    "        return truepos, falsepos, trueneg, falseneg\n",
    "    \n",
    "    def accuracy(self , y_actual , y_out): \n",
    "        acc = np.sum(y_actual == y_out)/len(y_out)\n",
    "        return acc\n",
    "    \n",
    "    def precision(self, y_actual, y_out):\n",
    "        tp, fp, tn, fn = self.metricscore(y_actual, y_out)\n",
    "        prec = tp/(tp + fp)\n",
    "        return prec\n",
    "    \n",
    "    def recall(self, y_actual, y_out):\n",
    "        tp, fp, tn, fn = self.metricscore(y_actual, y_out)\n",
    "        rec = tp/(tp + fn)\n",
    "        return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0b130c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic\n",
      "0.9308510638297872\n",
      "1.0\n",
      "0.8289473684210527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12368\\1476282826.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  sig = 1/(1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MiniBatch\n",
      "0.9468085106382979\n",
      "0.9459459459459459\n",
      "0.9210526315789473\n",
      "\n",
      "Batch\n",
      "0.9574468085106383\n",
      "0.9722222222222222\n",
      "0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "learnrate=0.01\n",
    "batchSize=5\n",
    "epochs=100\n",
    "threshold = 0.7\n",
    "\n",
    "#Stochastic\n",
    "LR1 = Logreg()\n",
    "LR1.graddesc(X_train, y_train, learnrate)\n",
    "test1_acc = LR1.accuracy(y_test, LR1.classify(X_test, threshold))\n",
    "test1_prec = LR1.precision(y_test, LR1.classify(X_test, threshold))\n",
    "test1_rec = LR1.recall(y_test, LR1.classify(X_test, threshold))\n",
    "print('Stochastic')\n",
    "print(test1_acc)\n",
    "print(test1_prec)\n",
    "print(test1_rec)\n",
    "\n",
    "#MiniBatch\n",
    "LR2 = MiniBatchLogreg()\n",
    "LR2.graddesc(X_train, y_train, learnrate, batchSize, epochs)\n",
    "test2_acc = LR2.accuracy(y_test, LR2.classify(X_test, threshold))\n",
    "test2_prec = LR2.precision(y_test, LR2.classify(X_test, threshold))\n",
    "test2_rec = LR2.recall(y_test, LR2.classify(X_test, threshold))\n",
    "print('\\nMiniBatch')\n",
    "print(test2_acc)\n",
    "print(test2_prec)\n",
    "print(test2_rec)\n",
    "\n",
    "#Batch\n",
    "LR3 = BatchLogreg()\n",
    "LR3.graddesc(X_train, y_train, learnrate, epochs)\n",
    "test3_acc = LR3.accuracy(y_test, LR3.classify(X_test, threshold))\n",
    "test3_prec = LR3.precision(y_test, LR3.classify(X_test, threshold))\n",
    "test3_rec = LR3.recall(y_test, LR3.classify(X_test, threshold))\n",
    "print('\\nBatch')\n",
    "print(test3_acc)\n",
    "print(test3_prec)\n",
    "print(test3_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946edae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
